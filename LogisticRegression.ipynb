{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLbL-LlnOAgm"
      },
      "source": [
        "# Homework 3 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aSWrpaElDM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a3588d-c07e-4489-b1d3-0823bfc2e957"
      },
      "source": [
        "# Add import statements here\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDvZ5xhsl9XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def58e15-b289-4805-ae96-88682597e7dd"
      },
      "source": [
        "# To access files in your Google Drive, run this block and follow the instructions\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi_dRrJDmtiI"
      },
      "source": [
        "# To test if the above block worked, run this block\n",
        "!ls '/content/gdrive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1rrY8fIxz7h"
      },
      "source": [
        " ## Find test error\n",
        "\n",
        "The `find_test_error` function computes the test error of a linear classifier $w$. \n",
        "\n",
        "The hypothesis is assumed to be of the form $sign([1, x(N,:)] \\cdot w)$.\n",
        "\n",
        "Inputs:\n",
        "* `w` is the weight vector\n",
        "* `X` is the data matrix (without an initial column of 1's)\n",
        "* `y` are the data labels (plus or minus 1)\n",
        "\n",
        "Outputs:\n",
        "* `test_error` is the binary error of $w$ on the data set $(X, y)$ error; this should be between 0 and 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BCKbvjMlHtE"
      },
      "source": [
        "def find_test_error(w, X, y):\n",
        "\n",
        "  # Your code here, assign the proper value to test_error:\n",
        "  temp = np.ones((np.size(X,0), 1), dtype = float)\n",
        "  X = np.concatenate((temp, X), axis = 1)\n",
        "  Xw = np.dot(X,w)\n",
        "  tlabel = np.sign(Xw)\n",
        "  # print('tlabel', tlabel)\n",
        "  sumarray = np.ones((np.size(X,0), 1), dtype = float)\n",
        "  for i in range(np.size(X,0)):\n",
        "    if y[i] == tlabel[i]:\n",
        "      sumarray[i] = 0\n",
        "    else:\n",
        "      sumarray[i] = sumarray[i] / np.size(X,0)\n",
        "  test_error = sum(sumarray)\n",
        "  return test_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUF6Mr1V0S5T"
      },
      "source": [
        " ## Logistic Regression\n",
        "\n",
        "The `logistic_reg`  learn a logistic regression model using gradient descent.\n",
        "\n",
        "Inputs:\n",
        "* `X` is the data matrix (without an initial column of 1's)\n",
        "* `y` are the data labels (plus or minus 1)\n",
        "* `w_init` is the initial value of the w vector ($d+1$ dimensional)\n",
        "* `max_its` is the maximum number of iterations to run for\n",
        "* `eta` is the learning rate\n",
        "\n",
        "Outputs:\n",
        "* t is the number of iterations gradient descent ran for\n",
        "* w is the learned weight vector\n",
        "* e_in is the in-sample (cross-entropy) error "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTcJkPE6lHvg"
      },
      "source": [
        "def logistic_reg(X, y, w_init, max_its, eta):\n",
        "\n",
        "  # Your code here, assign the proper values to t, w, and e_in:\n",
        "  startT = time.time()\n",
        "  onesArr = np.ones((np.size(X,0), 1), dtype = float)\n",
        "  X = np.concatenate((onesArr, X), axis = 1)\n",
        "  wold = w_init\n",
        "  nitr = 0\n",
        "  n = np.size(X,0)\n",
        "  tol = 0.1\n",
        "  wnew = np.array([])\n",
        "  while tol > 0.001 and nitr < max_its:\n",
        "    Xwold = np.dot(X, wold)\n",
        "    yXwold = np.multiply(y, np.transpose(Xwold))\n",
        "    denom = 1 + np.exp(yXwold)\n",
        "    gval = np.multiply(np.transpose(X), y) / denom\n",
        "    g = -gval.sum(axis=1) / n\n",
        "    wnew = np.subtract(np.transpose(wold), eta*g)\n",
        "    wnew = np.transpose(wnew)\n",
        "    wold = wnew\n",
        "    nitr = nitr + 1\n",
        "    tol = np.absolute(g).max()\n",
        "  print(nitr)\n",
        "  w = wnew\n",
        "  einval = np.log(1 + np.exp(-1 * np.multiply(y,np.transpose(np.dot(X, w)))))\n",
        "  e_in = np.sum(einval) / n\n",
        "  endT = time.time()\n",
        "  t = endT - startT\n",
        "  return t, w, e_in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bhZ8_HExVLy"
      },
      "source": [
        "Logistic Regression for part b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dsnXHMtww0o"
      },
      "source": [
        "def logistic_reg2(X, y, w_init, eta):\n",
        "  # Your code here, assign the proper values to t, w, and e_in:\n",
        "  startT = time.time()\n",
        "  onesArr = np.ones((np.size(X,0), 1), dtype = float)\n",
        "  X = np.concatenate((onesArr, X), axis = 1)\n",
        "  wold = w_init\n",
        "  nitr = 0\n",
        "  n = np.size(X,0)\n",
        "  tol = 0.1\n",
        "  wnew = np.array([])\n",
        "  while tol > 0.000001:\n",
        "    Xwold = np.dot(X, wold)\n",
        "    yXwold = np.multiply(y, np.transpose(Xwold))\n",
        "    denom = 1 + np.exp(yXwold)\n",
        "    gval = np.multiply(np.transpose(X), y) / denom\n",
        "    g = -gval.sum(axis=1) / n\n",
        "    wnew = np.subtract(np.transpose(wold), eta*g)\n",
        "    wnew = np.transpose(wnew)\n",
        "    wold = wnew\n",
        "    nitr = nitr + 1\n",
        "    tol = np.absolute(g).max()\n",
        "  w = wnew\n",
        "  einval = np.log(1 + np.exp(-1 * np.multiply(y,np.transpose(np.dot(X, w)))))\n",
        "  e_in = np.sum(einval) / n\n",
        "  endT = time.time()\n",
        "  t = endT - startT\n",
        "  return t, w, e_in, nitr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxt4wwMmwwL4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7d-boqb0y_H"
      },
      "source": [
        "## Run and Plot\n",
        "\n",
        "Run your code and plot figures below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWHPRXv4lHx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1290cd-9788-443d-9217-2820ab8d1876"
      },
      "source": [
        "%xmode Plain\n",
        "%pdb off\n",
        "# Other code here:\n",
        "#Question 1 part a\n",
        "#importing csv files and converting them to numpy arrays\n",
        "rawtrain = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/CSVfiles/clevelandtrain.csv')\n",
        "rawtest = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/CSVfiles/clevelandtest.csv')\n",
        "rawtrain = rawtrain.to_numpy()\n",
        "rawtest = rawtest.to_numpy()\n",
        "\n",
        "#creating x matrix and y arrray for test and train sets\n",
        "xtrain = rawtrain[:, range(0,13)]\n",
        "ytrain = rawtrain[:, 13]\n",
        "xtest = rawtest[:, range(0,13)]\n",
        "ytest = rawtest[:, 13]\n",
        "\n",
        "#changing y from 1&0 to -1&1\n",
        "#y = [2 * ph - 1 for ph in y]\n",
        "ytrain = ymodifier(ytrain)\n",
        "ytest = ymodifier(ytest)\n",
        "\n",
        "#finding logistic regression\n",
        "time10k, weight10k, ein10k = logistic_reg(xtrain, ytrain, np.zeros((14,1)), 10000, 0.00001)\n",
        "print(time10k, ein10k)\n",
        "time100k, weight100k, ein100k = logistic_reg(xtrain, ytrain, np.zeros((14,1)), 100000, 0.00001)\n",
        "print(time100k, ein100k)\n",
        "time1mil, weight1mil, ein1mil = logistic_reg(xtrain, ytrain, np.zeros((14,1)), 1000000, 0.00001)\n",
        "print(time1mil, ein1mil)\n",
        "\n",
        "#finding test error of train set\n",
        "trainError10k = find_test_error(weight10k, xtrain, ytrain)\n",
        "trainError100k = find_test_error(weight100k, xtrain, ytrain)\n",
        "trainError1mil = find_test_error(weight1mil, xtrain, ytrain)\n",
        "print(trainError10k)\n",
        "print(trainError100k)\n",
        "print(trainError1mil)\n",
        "\n",
        "#finging test error of test set\n",
        "testError10k = find_test_error(weight10k, xtest, ytest)\n",
        "testError100k = find_test_error(weight100k, xtest, ytest)\n",
        "testError1mil = find_test_error(weight1mil, xtest, ytest)\n",
        "print(testError10k)\n",
        "print(testError100k)\n",
        "print(testError1mil)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Plain\n",
            "Automatic pdb calling has been turned OFF\n",
            "10000\n",
            "0.4043424129486084 0.5847145522443018\n",
            "100000\n",
            "4.098693132400513 0.49370175927710563\n",
            "1000000\n",
            "40.32430100440979 0.43535260915252544\n",
            "[0.30921053]\n",
            "[0.22368421]\n",
            "[0.15131579]\n",
            "[0.31724138]\n",
            "[0.20689655]\n",
            "[0.13103448]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXsLnHEls3y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2851586-4304-406b-f021-ed84c1a21ad9"
      },
      "source": [
        "%xmode Plain\n",
        "%pdb off\n",
        "# Question 1 part b\n",
        "rawtrain = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/CSVfiles/clevelandtrain.csv')\n",
        "rawtest = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/CSVfiles/clevelandtest.csv')\n",
        "rawtrain = rawtrain.to_numpy()\n",
        "rawtest = rawtest.to_numpy()\n",
        "\n",
        "# creating x matrix and y arrray for test and train sets\n",
        "xtrain = rawtrain[:, range(0,13)]\n",
        "ytrain = rawtrain[:, 13]\n",
        "xtest = rawtest[:, range(0,13)]\n",
        "ytest = rawtest[:, 13]\n",
        "\n",
        "#changing y from 1&0 to -1&1\n",
        "#y = [2 * ph - 1 for ph in y]\n",
        "ytrain = ymodifier(ytrain)\n",
        "ytest = ymodifier(ytest)\n",
        "\n",
        "# calculating mean and sd of x matrix from training set\n",
        "meanArr = np.mean(xtrain, axis = 0) \n",
        "sdArr = np.std(xtrain, axis = 0)\n",
        "\n",
        "#calculating zscore different way with stats\n",
        "# zXtrain = stats.zscore(xtrain, axis=0)\n",
        "\n",
        "# scaling xtrain and xtest\n",
        "scaleXtrain = (xtrain - meanArr) / sdArr\n",
        "scaleXtest = (xtest - meanArr) / sdArr\n",
        "\n",
        "# running logistic regression at different learning rates\n",
        "lr = [0.01, 0.1, 1, 4, 5, 6, 7, 7.5, 7.6, 7.65]\n",
        "timelr1, wlr1, einlr1, iterlr1 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[0])\n",
        "print('learning rate 0.01', 'time', timelr1, 'e_in', einlr1, 'iterations', iterlr1)\n",
        "timelr2, wlr2, einlr2, iterlr2 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[1])\n",
        "print('learning rate 0.1', 'time', timelr2, 'e_in', einlr2, 'iterations', iterlr2)\n",
        "timelr3, wlr3, einlr3, iterlr3 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[2])\n",
        "print('learning rate 1', 'time', timelr3, 'e_in', einlr3, 'iterations', iterlr3)\n",
        "timelr4, wlr4, einlr4, iterlr4 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[3])\n",
        "print('learning rate 4', 'time', timelr4, 'e_in', einlr4, 'iterations', iterlr4)\n",
        "timelr5, wlr5, einlr5, iterlr5 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[4])\n",
        "print('learning rate 5', 'time', timelr5, 'e_in', einlr5, 'iterations', iterlr5)\n",
        "timelr6, wlr6, einlr6, iterlr6 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[5])\n",
        "print('learning rate 6', 'time', timelr6, 'e_in', einlr6, 'iterations', iterlr6)\n",
        "timelr7, wlr7, einlr7, iterlr7 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[6])\n",
        "print('learning rate 7', 'time', timelr7, 'e_in', einlr7, 'iterations', iterlr7)\n",
        "timelr8, wlr8, einlr8, iterlr8 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[7])\n",
        "print('learning rate 7.5', 'time', timelr8, 'e_in', einlr8, 'iterations', iterlr8)\n",
        "timelr9, wlr9, einlr9, iterlr9 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[8])\n",
        "print('learning rate 7.6', 'time', timelr9, 'e_in', einlr9, 'iterations', iterlr9)\n",
        "timelr10, wlr10, einlr10, iterlr10 = logistic_reg2(scaleXtest, ytest, np.zeros((14,1)), lr[9])\n",
        "print('learning rate 7.65', 'time', timelr10, 'e_in', einlr10, 'iterations', iterlr10)\n",
        "\n",
        "# test and train errors\n",
        "testErrorLr1 = find_test_error(wlr1, scaleXtest, ytest)\n",
        "trainErrorLr1 = find_test_error(wlr1, scaleXtrain, ytrain)\n",
        "print('trainError for lr = 0.01', trainErrorLr1, 'testError for lr = 0.01', testErrorLr1)\n",
        "testErrorLr10 = find_test_error(wlr10, scaleXtest, ytest)\n",
        "trainErrorLr10 = find_test_error(wlr10, scaleXtrain, ytrain)\n",
        "print('trainError for lr = 7.65', trainErrorLr10, 'testError for lr = 7.65', testErrorLr10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Plain\n",
            "Automatic pdb calling has been turned OFF\n",
            "learning rate 0.01 time 2.976383686065674 e_in 0.23065415514539747 iterations 74909\n",
            "learning rate 0.1 time 0.31060266494750977 e_in 0.23065415514489573 iterations 7487\n",
            "learning rate 1 time 0.03164958953857422 e_in 0.23065415513855675 iterations 745\n",
            "learning rate 4 time 0.008558034896850586 e_in 0.2306541551199055 iterations 180\n",
            "learning rate 5 time 0.007134914398193359 e_in 0.23065415510966955 iterations 140\n",
            "learning rate 6 time 0.00652623176574707 e_in 0.23065415511056597 iterations 109\n",
            "learning rate 7 time 0.003779172897338867 e_in 0.23065415500165967 iterations 65\n",
            "learning rate 7.5 time 0.005596160888671875 e_in 0.2306541550964868 iterations 83\n",
            "learning rate 7.6 time 0.0052394866943359375 e_in 0.23065415509649165 iterations 84\n",
            "learning rate 7.65 time 0.005105495452880859 e_in 0.23065415508144665 iterations 85\n",
            "trainError for lr = 0.01 [0.19078947] testError for lr = 0.01 [0.10344828]\n",
            "trainError for lr = 7.65 [0.19078947] testError for lr = 7.65 [0.10344828]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3mrOrbBLQuC"
      },
      "source": [
        "def ymodifier(y):\n",
        "  ymod = 2*y-1\n",
        "  return ymod"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}