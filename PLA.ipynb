{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6yoNm3tRqH7"
      },
      "source": [
        "# Homework 1 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvle6XQTWWrZ"
      },
      "source": [
        "# Add import statements here\n",
        "import numpy as np\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "becadmSx8_Aw"
      },
      "source": [
        "## Perceptron Learning\n",
        "\n",
        "The `perceptron_learn` function runs the Perceptron Learning Algorithm on input data.\n",
        "\n",
        "Inputs: \n",
        "* `data_in` is a matrix with each row representing an $(x, y)$ pair; the $x$ vector is augmented with a leading 1, the label, $y$, is in the last column. \n",
        "Outputs:\n",
        "The function outputs a tuple, `(w, iterations)`, where: \n",
        "* `w` is the learned weight vector; it should linearly separate the data if it is linearly separable.\n",
        "* `iterations` is the number of iterations the algorithm ran for. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSIE8o_7-nMI"
      },
      "source": [
        "def perceptron_learn(data_in):\n",
        "\n",
        "  # Your code here, assign the proper values to w and iterations: \n",
        "  narray = data_in.shape\n",
        "  # Getting number of rows and columns\n",
        "  inrow = narray[0]\n",
        "  incol = narray[1]\n",
        "  tlabel = narray[0:(inrow), incol-1]\n",
        "  w = np.zeros((1,incol-1))\n",
        "  iterations = 0\n",
        "  while np.sign(w*narray[0:(inrow), 0:(incol-1)], tlabel) == 0:\n",
        "    index1 = np.argwhere(np.sign(w*narray[0:(inrow), 0:(incol-1)]) - tlabel != 0)\n",
        "    w = w + narray(index1[0], incol)*narray(index1[0], incol-1)\n",
        "    iterations = iterations + 1\n",
        "  return w, iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49dBCflt_YHw"
      },
      "source": [
        "# Perceptron Experiment\n",
        "Code for running the perceptron experiment in HW1. \n",
        "\n",
        "Inputs: \n",
        "* `N` is the number of training examples\n",
        "* `d` is the dimensionality of each example (before adding the 1)\n",
        "* `num_samples` is the number of times to repeat the experiment\n",
        "\n",
        "Outputs:\n",
        "* `num_iters` is the number of iterations the Perceptron Learning Algorithm takes for each sample\n",
        "* `bound_minus_ni` is the difference between the theoretical bound and the actual number of iterations\n",
        "\n",
        "Both outputs should be `num_samples` long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk1iKwL7AirD"
      },
      "source": [
        "def perceptron_experiment(N, d, num_samples):\n",
        "\n",
        "  # Your code here, assign the values to num_ters and bounds_minus_ni:\n",
        "  num_ters = np.zeros((1, num_samples))\n",
        "  bounds = np.zeros((1, num_samples))\n",
        "  for i in range(0, num_samples):\n",
        "    wstar = np.random.rand(1, d+1)\n",
        "    wstar[0] = 0;\n",
        "    x = 2*np.random.rand(d+1, N-1)\n",
        "    x[0, 0:N] = np.ones((1,N))\n",
        "    cortag = np.sign(np.matmul(wstar*x))\n",
        "    array = np.array([x, cortag])\n",
        "    perlearn = perceptron_learn(array)\n",
        "    w = perlearn[0]\n",
        "    iterat = perlearn[1]\n",
        "    num_ters[i] = iterat\n",
        "\n",
        "    rho  = np.amin(np.multiply(cortag,(wstar*x))\n",
        "    testing = np.multiply(x, x)\n",
        "    r2 = np.amax(sum(np.multiply(x,x), len(np.multiply(x,x))))\n",
        "    w2 = sum((np.multiply(wstar, wstar), len(np.multiply(wstar,wstar)))\n",
        "    bounds[i] = r2*w2/(rho^2)\n",
        "    bounds_minus_ni = bounds - num_ters\n",
        "  return num_iters, bounds_minus_ni"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3wzw3SvB5mE"
      },
      "source": [
        "## Run and Plot\n",
        "\n",
        "Run the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXvSa5MVKfg"
      },
      "source": [
        "answer = perceptron_experiment(100, 10, 1000)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}